---
title: Causal Inference Homework Assignment 4
subtitle: The role of propensity scores in observational study
author: Alan Z Chen, Chansoo Song
date: "`r format(Sys.time(), '%B %Y')`"
header-includes:
    - \usepackage{amsmath}
output: pdf_document
---

```{r rmd_setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(include=TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)
knitr::opts_knit$set(root.dir='..')
```

```{r rmd, message=FALSE}
library(arm)
library(ggplot2)
library(rlang)
library(RColorBrewer)
library(stats)
library(Hmisc)
library(caret)
library(randomForest)
library(nnet)
library(dplyr)
library(MatchIt)

rm(list=ls())
# Set global ggplot theme
theme_set(theme_minimal())
# Define global color palettes
col.RdBl.2 <- brewer.pal(3, 'RdBu')[-2]
```


# Objective  
This assignment will give you the opportunity to practice several different propensity score approaches to causal inference. In addition you will be asked to interpret the resulting output and discuss the assumptions necessary for causal inference.


# Problem Statement  
In this assignment will use data from a constructed observational study. The data and an associated data dictionary are available in this folder. The treatment group for the study that the data are drawn from is the group of children who participated in the IHDP intervention discussed in class. The research question of interest focuses on the effect of the IHDP intervention on age 3 IQ scores for the children that participated in it. The data for the comparison sample of children was pulled from the National Longitudinal Study of Youth during a similar period of time that the data were collected for the IHDP study.


## Question 1: Load the data and choose confounders (Step 1)

\texttt{ANSWER:}
```{r Q1}
load('data/hw4.rdata')

# Pick confounders based on correlation to treatment and outcome variables
corr_mat <- cor(hw4)
corr_mat <- rbind(corr_mat['treat',], corr_mat['ppvtr.36',])
confounders <- names(which((abs(corr_mat[1,]) > 0.3) + (abs(corr_mat[2,]) > 0.3) > 0))
confounders <- confounders[!(confounders %in% c('treat', 'ppvtr.36'))]
# Remove post-treatment variables
confounders <- confounders[!(confounders %in% c('dayskidh', 'income'))]
# Replace momed with dummy variables
if ('momed' %in% confounders) {
    confounders <- c(confounders[!(confounders %in% 'momed')], c('lths', 'hs', 'ltcoll', 'college'))
}

# Subset data for analysis
dt <- hw4[hw4$bw<3000, c('ppvtr.36', 'treat', confounders)]
```


## Question 2: Estimate the propensity score (Step 2)

\texttt{ANSWER:}
```{r Q2}
ps.m1 <- glm(treat ~ ., data=dt[, c('treat',confounders)], family=binomial(link='logit'))
dt$psc <- ps.m1$fitted.values
plot(dt$psc)
```


## Question 3: Restructure your data through matching. [Or at least create the weights variable that will let you to do so in the following steps] (Step 3)

- (a) The first thing you need to be clear on before restructuring your data is the estimand. Given the description above about the research question, what is the estimand of interest?  
- (b) First please perform *one-to-one nearest neighbor matching with replacement* using your estimated propensity score from Question 2. Perform this matching using the `matching` command in the arm package. The *"cnts"* variable in the output reflects the number of times each control observation was used as a match (the length is equal to the number of control observations). Use the output of this function to create a weight variable that  
- 1) equals one for treated observations and  
- 2) equals the number of times used as a match for non- treated observations.  

\texttt{ANSWER:}  
The IHDP intervention targeted children that were born premature and with low birth weight, thus the estimand of interest is the \texttt{ATT} (average treatment effect for the treated).

```{r Q3}
matches <- matching(z=dt$treat, score=dt$psc, replace=TRUE)
dt[dt$treat==0, 'wt'] <- matches$cnts
dt[dt$treat==1, 'wt'] <- 1
```


## Question 4: Check overlap and balance. (Step 4)

### (a) Examining Overlap. Check overlap on the *unmatched* data using some diagnostic plots. Check overlap for the propensity scores as well as two other covariates.

\texttt{ANSWER:}
```{r Q4a}
# Paired, inverted histograms: propensity scores
examine_overlap = function(dt, nbins=40, var='psc', var_name='Propensity Score', xlab='Propensity Score', ylim=c(-30,50), options=NULL){

    dt_plot = dt[, c('treat', var)]
    colnames(dt_plot) = c('treat', 'X')
    
    ggplot(dt_plot) +
        geom_histogram(data=dt_plot[dt_plot$treat==0,], bins=nbins, fill='grey', alpha=0.1, aes(X, y=..count.., color=col.RdBl.2[2])) +
        geom_histogram(data=dt_plot[dt_plot$treat==1,], bins=nbins, fill='grey', alpha=0.1, aes(X, y=-..count.., color=col.RdBl.2[1])) +
        coord_cartesian(ylim=ylim) +
        scale_color_manual(values=rev(col.RdBl.2), labels=c('Control', 'Treated'), name='') +
        labs(x=xlab, y='Frequency', title=paste('Overlap of ', var_name, ' between Groups', sep='')) +
        options 
}

# Overlap of propensity score
examine_overlap(dt, nbins=40, var='psc', var_name='Propensity Score', xlab='Propensity Score', ylim=c(-30,50))
# Overlap of preterm
examine_overlap(dt, nbins=20, var='preterm', var_name='Number Weeks Baby Born Preterm', xlab='Weeks Preterm', ylim=c(-100,150))
# Overlap of birth weight
examine_overlap(dt, nbins=20, var='bw', var_name='Birth weight', xlab='Birth weight', ylim=c(-50,200))
```

### (b) Interpreting Overlap. What do these plots reveal about the overlap required to estimate our estimand of interest.

\texttt{ANSWER:}  
Since our estimand of interest is the \texttt{ATT}, we need similar observations from the control group to use as our counterfactuals for the treatment group. The plots above show sufficient overlap (relative to the treated) between the two groups in propensity scores, number of weeks the baby was born preterm, child's birth weight, and days child was in hospital after birth.

### (c) Examining Balance. You will build your own function to check balance! This function should take as inputs the data frame created in Question 1, the vector with the covariate names chosen in Question 1, and the weights created in Question 2. It should output the following:  

- 1) Mean in the unmatched treatment group  
- 2) Mean in the unmatched control group  
- 3) Mean in the matched treatment group  
- 4) Mean in the matched control group  
- 5) Unmatched mean difference (standardized for continuous variables, not standardized for binary variables)  
- 6) Matched mean difference (standardized for continuous variables, not standardized for binary variables)  
- 7) Ratio of standard deviations across unmatched groups (control/treated)  
- 8) Ratio of standard deviations across matched groups (control/treated)

\texttt{ANSWER:}
```{r Q4c}
checkBalance = function(df, confounders, wt_var, digits=3) {

    # Subset data to confounders only
    df2 <- df[, confounders]

    binary = apply(df2, 2, function(x) all(x %in% 0:1)) # Binary Variable Indicator
    trt = df$treat == 1                   # Treatment Indicator
    ctr = df$treat == 0                   # Control Indicator
    n_trt = sum(trt)                      # Treatment Sample Size
    n_ctrl = sum(ctr)                     # Control Sample Size
    wts.trt = df[trt, wt_var]              # Set treatment weights
    wts.ctr = df[ctr, wt_var]  # Set control weights
  
    # Means
    trt.means = apply(df2[trt,], 2, mean)
    trt.means_w = apply(df2[trt,], 2, wtd.mean, wts.trt)
    ctr.means = apply(df2[ctr,], 2, mean)
    ctr.means_w = apply(df2[ctr,], 2, wtd.mean, wts.ctr)
  
    # Variances
    trt.var = apply(df2[trt,], 2, var)
    trt.var_w = apply(df2[trt,], 2, function(x) sum(wts.trt * (x - wtd.mean(x, wts.trt))^2) / (sum(wts.trt) - 1))
    ctr.var = apply(df2[ctr,], 2, var)
    ctr.var_w = apply(df2[ctr,], 2, function(x) sum(wts.ctr * (x - wtd.mean(x, wts.ctr))^2) / (sum(wts.ctr) - 1))
  
    # Standardized Mean Differences
    mean.diff = (trt.means-ctr.means) / sqrt(trt.var)
    mean.diff.bin = (trt.means-ctr.means)
    diff = mean.diff * (1-binary) + mean.diff.bin * binary
  
    mean.diff_w = (trt.means_w-ctr.means_w) / sqrt(trt.var_w)
    mean.diff.bin_w = (trt.means_w-ctr.means_w)
    diff.m = mean.diff_w*(1-binary) + mean.diff.bin_w*binary
  
    # Ratios of standard deviations
    ratio = sqrt(ctr.var)/sqrt(trt.var)
    ratio[binary] = NA

    ratio.m = sqrt(ctr.var_w)/sqrt(trt.var_w)
    ratio.m[binary] = NA
  
    # Return results
    result = cbind(trt.means, ctr.means, trt.means, ctr.means_w, diff, diff.m, ratio, ratio.m)
    colnames(result) = c('mn1', 'mn0', 'mn1.m', 'mn0.m', 'diff', 'diff.m', 'ratio', 'ratio.m')
    return(round(result, digits))
}
```

### (d) How do you interpret the resulting balance? In particular what are your concerns with regard to covariates that are not well balanced (write about 5 or 6 sentences).

\texttt{ANSWER:}
```{r Q4d}
ps.m1.bal <- checkBalance(df=dt, confounders=confounders, wt_var='wt')
ps.m1.bal
```

### (e) Unit test. Show the results of your balance function on a simple example with the same sample as above (that is, limited to children with birth weight less than 3000) where the propensity score is fit using logistic regression on “bw” and “b.marr” and the matching is performed using 1-1 nearest neighbor matching with replacement. The output of your balance function should match the following (when rounded to 3 decimal places):

\texttt{ANSWER:}
```{r Q4e}
# Subset data
temp <- hw4[hw4$bw<3000, c('treat', 'bw', 'b.marr')]
# Fit propensity score model (logistic)
ps.temp <- glm(treat ~ bw + b.marr, data=temp, family=binomial(link='logit'))
# Generate propensities scores
temp$psc <- ps.temp$fitted.values
# 1-1 nearest neighbor matching with replacement
ps.temp.matches <- matching(z=temp$treat, score=temp$psc, replace=TRUE)
temp[temp$treat==0, 'wt'] <- ps.temp.matches$cnts
temp[temp$treat==1, 'wt'] <- 1

checkBalance(temp, c('bw', 'b.marr'), 'wt')
```


## Question 5: Repeat steps 2-4 within the matching framework.

\texttt{ANSWER:}
Fit new propensity score models:
```{r Q5.probit}
# Model 2: Probit
ps.m2 <- glm(treat ~ ., data=dt[, c('treat', confounders)], family=binomial(link='probit'))
summary(ps.m2)
dt$psc_probit <- ps.m2$fitted.values
confusionMatrix(factor(ifelse(dt$psc_probit>0.5,1,0)), factor(dt$treat))
```

```{r Q5.probit.i}
# Model 3: Probit with interactions
ps.m3 <- glm(treat ~ .^2, data=dt[, c('treat', confounders)], family=binomial(link='probit'))
summary(ps.m3)
dt$psc_full <- ps.m3$fitted.values
confusionMatrix(factor(ifelse(dt$psc_full>0.5,1,0)), factor(dt$treat))
```

```{r Q5.randomForest}
# Model 4: Random Forest
m.rf = randomForest(as.factor(treat) ~ ., data=dt[, c('treat', confounders)], ntree = 10)
dt$psc_rf = predict(m.rf, dt, type="prob")[,2]
confusionMatrix(factor(ifelse(dt$psc_rf>0.5,1,0)), factor(dt$treat))
```

```{r Q5.neuralNet}
# Model 5: Neural Net
dt_nnet = as.data.frame(dt[, c('treat', confounders)])
dt_nnet[, which(sapply(dt_nnet, class)=="numeric")] = scale(dt_nnet[, which(sapply(dt_nnet, class)=="numeric")])
dt_nnet$treat = as.factor(dt_nnet$treat)

nn_mod = nnet(treat ~ ., data=dt_nnet, size=8, linout=FALSE, maxit=200)
dt$psc_nn = as.numeric(predict(nn_mod))
confusionMatrix(factor(ifelse(dt$psc_nn>0.5,1,0)), factor(dt$treat))
```

Matching with new models:
```{r Q5.match}
# Matches
matches <- matching(z=dt$treat, score=dt$psc_probit, replace=TRUE)
dt[dt$treat==1, 'wt.probit'] <- 1
dt[dt$treat==0, 'wt.probit'] <- matches$cnt

matches <- matching(z=dt$treat, score=dt$psc_full, replace=TRUE)
dt[dt$treat==1, 'wt.full'] <- 1
dt[dt$treat==0, 'wt.full'] <- matches$cnts

matches <- matching(z=dt$treat, score=dt$psc_rf, replace=TRUE)
dt[dt$treat==1, 'wt.rf'] <- 1
dt[dt$treat==0, 'wt.rf'] <- matches$cnts

matches <- matching(z=dt$treat, score=dt$psc_nn, replace=TRUE)
dt[dt$treat==1, 'wt.nn'] <- 1
dt[dt$treat==0, 'wt.nn'] <- matches$cnts
```
Calculate the Mahalanobis distance for matching:
```{r Q5.mahalanobis}
# Mahalanobis Distance
myMH = function(trtnms, ctrnms, inv.cov, df) {
    # Helper function: calculates mahalanobis distance between a pair of treated and control observations
    covars <- dimnames(inv.cov)[[1]]
    xdiffs <-as.matrix(df[trtnms, covars]) - as.matrix(df[ctrnms, covars])
    sqrt(rowSums((xdiffs %*% inv.cov) * xdiffs))
}

mahaloMahalanobis = function(df, confounders) {
    # Calculate mahalanobis distance for all treated X control pairs
    inv_cov_mat = solve(cov(df[, confounders]), tol=1e-24)
    treated = row.names(df[df$treat==1,])
    controls = row.names(df[df$treat==0,])
    return( outer(treated, controls, FUN=myMH, inv.cov=inv_cov_mat, data=df) )
}

matchMahalanobis = function(mhDistMat, df) {
    # Return 'cnts' for controls for Mahalanobis 1-1 matching with replacement
    
    controls = data.frame(ctrl=seq(nrow(df[df$treat==0,])))
    # For each treated find matched control
    matched = apply(mhDistMat, 1, function(i) min(which(i==min(i))))
    matched.count <- data.frame(table(matched))
    matches = merge(controls, matched.count, by.x='ctrl', by.y='matched', all.x=TRUE)
    matches[is.na(matches$Freq), 'Freq'] <- 0
    return(matches[['Freq']])
}

# Calculate mahalanobis distance matrix
mahalanobisDist = mahaloMahalanobis(dt, confounders)
# 1-1 matching with replacement
dt[dt$treat==0, 'wt.mh'] = matchMahalanobis(mahalanobisDist, dt)
dt[dt$treat==1, 'wt.mh'] = 1
```

Check overlap and balance:
```{r Q5.overlap}
# OVERLAP
# Paired, inverted histograms: propensity scores
examine_overlap(dt, 40, var='psc_probit', var_name='Propensity Score (Probit Model)', xlab='Propensity Score', ylim=c(-30,50))
examine_overlap(dt, 40, var='psc_full', var_name='Propensity Score (Probit Full Model)', xlab='Propensity Score', ylim=c(-30,50))
examine_overlap(dt, 40, var='psc_rf', var_name='Propensity Score (Random Forest Model)', xlab='Propensity Score', ylim=c(-30,50))
examine_overlap(dt, 40, var='psc_nn', var_name='Propensity Score (Neural Net Model)', xlab='Propensity Score', ylim=c(-30,50))

m1.bal = checkBalance(dt, confounders, 'wt')
probit.bal = checkBalance(dt, confounders, 'wt.probit')
full.bal = checkBalance(dt, confounders, 'wt.full')
rf.bal = checkBalance(dt, confounders, 'wt.rf')
nn.bal = checkBalance(dt, confounders, 'wt.nn')
mh.bal = checkBalance(dt, confounders, 'wt.mh')
```


## Question 6: Repeat steps 2-4, but this time using IPTW.

\texttt{ANSWER:}
```{r Q6}
# Code for Estimating the Propensity Score
ps.iptw <- glm(treat ~ ., data=dt[, c('treat',confounders)], family=binomial(link='logit'))
dt$psc_iptw <- ps.iptw$fitted.values

# Code for Creating the IPTW Weights
dt[dt$treat==1, 'wt.iptw'] <- 1
dt[dt$treat==0, 'wt.iptw'] <- dt[dt$treat==0, 'ps.iptw'] / (1 - dt[dt$treat==0, 'ps.iptw'])
```

For estimating the ATE, define the weight as follows:
$$\omega(Z,x) = \frac{Z}{\hat{\epsilon}(x)} + \frac{(1-Z)}{1-\hat{\epsilon(x)}}$$
```{r Q6.i}
r_ate = dt$treat/dt$psc + (1-dt$treat)/(1-dt$psc)
```


For estimating the ATT, define the weight as follows:
$$\omega(Z,x) = Z + (1-Z) * \frac{\hat{\epsilon}(x)}{1-\hat{\epsilon}(x)}$$
```{r Q6.ii}
r_att = dt$psc + (1-dt$treat) * dt$psc / (1-dt$psc)
```

```{r Q6.iii}
iptw.balance <- checkBalance(dt, confounders, r_att)
iptw.balance
```


### Question 7: Comparative balance table Create a table with columns 6 and 8 from your function for each of the matching and weighting methods performed above. Which approach would you choose and why? (1-2 paragraphs at most)

\texttt{ANSWER:}  



### Question 8: Estimate the treatment effect for the restructured datasets implied by Questions 4-6 (Step 5) 

Estimate the effect of the treatment on the treated for each of your five approaches by fitting a regression with weights equal to the number of times each observation appears in the matched sample (that is, use your weights variable from above) or using IPTW weights. Report the treatment effect and standard error for each approach.

\texttt{ANSWER:}
```{r Q8}
dt[dt$treat==0, 'w'] <- wts
dt[dt$treat==1, 'w'] <- 1
df = dt[,c('ppvtr.36','treat',confounders)]

mod1 = summary(lm(ppvtr.36 ~ ., data = df, weights = dt$w))$coefficients
mod1.out = c(mod1[2,1],mod1[2,2])

mod2 = summary(lm(ppvtr.36 ~ ., data = df, weights = dt$w_probit))$coefficients
mod2.out = c(mod2[2,1],mod2[2,2])

mod3 = summary(lm(ppvtr.36 ~ ., data = df, weights = dt$w_full))$coefficients
mod3.out = c(mod3[2,1],mod3[2,2])

mod4 = summary(lm(ppvtr.36 ~ ., data = df, weights = dt$w_mahalo))$coefficients
mod4.out = c(mod4[2,1],mod4[2,2])

mod5 = summary(lm(ppvtr.36 ~ ., data = df, weights = r_att))$coefficients
mod5.out = c(mod5[2,1],mod5[2,2])

q8_results = rbind(mod1.out,mod2.out,mod3.out,mod4.out,mod5.out)
row.names(q8_results) = c('logit','probit','full probit','mahalo','IPTW')
colnames(q8_results) = c('coef','se')
q8_results

plot(dt$w_probit)
plot(dt$w)
plot(dt$w_full)
plot(dt$w_mahalo)
```


### Question 9: Assumptions What assumptions are necessary to interpret the estimates from the propensity score approaches causally? List and describe briefly.

\texttt{ANSWER:}  



### Question 10: Causal Interpretation Provide a causal interpretation of *one* of your estimates above. Remember to specify the counterfactual and to be clear about whom you are making inferences. Also make sure to use causal (counterfactual) language.

\texttt{ANSWER:}  



### Question 11: Comparison to linear regression Fit a regression of your outcomes to the treatment indicator and covariates.

#### (a) Report your estimate and standard error.

\texttt{ANSWER:}
```{r Q11.a}
lm1 <- lm(ppvtr.36 ~ ., data=dt[, c(confounders, 'ppvtr.36', 'treat')])
round(summary(lm1)$coefficients['treat', c('Estimate', 'Std. Error'), drop=FALSE], 2)
```

#### (b) Interpret your results non-causally

\texttt{ANSWER:}  


#### (c) Why might we prefer the results from the propensity score approach to the linear regression results in terms of identifying a causal effect?

\texttt{ANSWER:}  

